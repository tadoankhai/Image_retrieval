{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qwen_vl_utils\n",
      "  Downloading qwen_vl_utils-0.0.11-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting av (from qwen_vl_utils)\n",
      "  Downloading av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: packaging in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from qwen_vl_utils) (24.2)\n",
      "Requirement already satisfied: pillow in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from qwen_vl_utils) (11.2.1)\n",
      "Requirement already satisfied: requests in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from qwen_vl_utils) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from requests->qwen_vl_utils) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from requests->qwen_vl_utils) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from requests->qwen_vl_utils) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages (from requests->qwen_vl_utils) (2025.1.31)\n",
      "Downloading qwen_vl_utils-0.0.11-py3-none-any.whl (7.6 kB)\n",
      "Downloading av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m837.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: av, qwen_vl_utils\n",
      "Successfully installed av-14.3.0 qwen_vl_utils-0.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install qwen_vl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atin/miniconda3/envs/khaitd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384.\n",
    "# You can set min_pixels and max_pixels according to your needs, such as a token range of 256-1280, to balance performance and cost.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Identify the pedestrian attributes below:\n",
    "1. Gender (e.g., male, female)\n",
    "2. Hair (style, length, and color)\n",
    "3. Eyeglasses (is the person wearing glasses?) \n",
    "4. Upper-body clothing (type and color)\n",
    "5. Lower-body clothing (type and color)\n",
    "6. Footwear (type and color)\n",
    "\n",
    "Based on the extracted information, write a single sentence in English, omit any details that are not visible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The pedestrian is a female with long black hair, wearing glasses, a black top, black pants, and black shoes.']\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/1e94383a-6503-4a5c-b3eb-7423dd1a2226.jpg\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/1e94383a-6503-4a5c-b3eb-7423dd1a2226.jpg\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=Image.open(img_path),\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST ####\n",
    "#### QWEN VL 7B Instruct ####\n",
    "linkimage_1 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/0cf57668-fe69-48fc-8da0-251e75289314.jpg\" # Đeo kính, áo trắng, quần vàng, giày trắng\n",
    "linkimage_2 = \"/home/atin/ai_t4/khaitd/Image_retrieval/crops/person_5.png\" # Áo vàng, tóc vàng\n",
    "linkimage_3 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/e9b914f1-b08e-4584-a7b5-65b2373477b0.jpg\" # Đeo kính, Áo đen, quần đen\n",
    "linkimage_4 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/0fad08ca-e8e1-4e5e-9e80-f68755dc0ee2.jpg\" # Áo ngắn màu đen, quần đen, giày trắng\n",
    "linkimage_5 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/1fdac95a-f3f8-4eca-aac9-d26ea0217b7a.jpg\" # Áo đen, quần đen, dép đen, đeo kính\n",
    "linkimage_6 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/2ce5b74f-88dc-4fb8-b9a2-9ffb184e2ab8.jpg\" # Phụ nữ, váy đen\n",
    "\n",
    "text_return_1 = 'The pedestrian is a male with short dark hair, wearing glasses, a white shirt, beige pants, and white sneakers.'\n",
    "text_return_2 = 'The pedestrian appears to be male with short dark hair, is not wearing glasses, and is dressed in a gray hoodie.'\n",
    "text_return_3 = 'The pedestrian appears to be male, with short dark hair, is not wearing glasses, is dressed in a dark-colored long-sleeve shirt and pants, and is wearing dark shoes.'\n",
    "text_return_4 = 'The pedestrian is a male with short dark hair, wearing a dark vest over a light-colored shirt, dark pants, and white sneakers.'\n",
    "text_return_5 = 'The pedestrian is a male with short black hair, wearing glasses, a black graphic t-shirt, black pants, and black sandals.'\n",
    "text_return_6 = 'The pedestrian is a female with short dark hair, wearing glasses, dressed in a black top and skirt, and white high-heeled shoes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST ####\n",
    "#### QWEN VL 7B Instruct ####\n",
    "linkimage_1 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/0cf57668-fe69-48fc-8da0-251e75289314.jpg\" # Đeo kính, áo trắng, quần vàng, giày trắng\n",
    "linkimage_2 = \"/home/atin/ai_t4/khaitd/Image_retrieval/crops/person_5.png\" # Áo vàng, tóc vàng\n",
    "linkimage_3 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/e9b914f1-b08e-4584-a7b5-65b2373477b0.jpg\" # Đeo kính, Áo đen, quần đen\n",
    "linkimage_4 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/0fad08ca-e8e1-4e5e-9e80-f68755dc0ee2.jpg\" # Áo ngắn màu đen, quần đen, giày trắng\n",
    "linkimage_5 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/1fdac95a-f3f8-4eca-aac9-d26ea0217b7a.jpg\" # Áo đen, quần đen, dép đen, đeo kính\n",
    "linkimage_6 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/2ce5b74f-88dc-4fb8-b9a2-9ffb184e2ab8.jpg\" # Phụ nữ, váy đen\n",
    "linkimage_7 = \"/home/atin/ai_t4/khaitd/Image_retrieval/Database/1e94383a-6503-4a5c-b3eb-7423dd1a2226.jpg\"\n",
    "\n",
    "text_return_1 = 'The pedestrian is a male with short, dark hair, wearing glasses, a white shirt, khaki pants, and white shoes.'\n",
    "text_return_2 = 'The pedestrian is a male with short black hair, wearing a grey hoodie and beige pants.'\n",
    "text_return_3 = 'The pedestrian is a male with short hair, wearing glasses, a dark-colored shirt, dark pants, and sneakers.'\n",
    "text_return_4 = 'The person is a male with short black hair, wearing a dark-colored shirt and brown pants.'\n",
    "text_return_5 = 'The pedestrian is a male with short black hair, wearing glasses, a black graphic t-shirt, black pants, and black sandals.'\n",
    "text_return_6 = 'The pedestrian is a female with short hair, wearing a black dress and high heels.'\n",
    "text_return_7 = 'The pedestrian is a female with long black hair, wearing glasses, a black top, black pants, and black shoes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khaitd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
